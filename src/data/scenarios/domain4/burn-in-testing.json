{
  "id": "domain4-burn-in",
  "title": "Cluster Burn-in Testing (NCCL, HPL, NeMo)",
  "domain": "domain4",
  "difficulty": "advanced",
  "description": "Perform extended burn-in tests using NCCL, HPL, and NeMo to validate cluster stability and performance over time. Essential for production readiness verification and identifying intermittent hardware issues that only appear under sustained load.",
  "learningObjectives": [
    "Execute NCCL burn-in for network stability validation",
    "Run HPL burn-in for compute and thermal validation",
    "Perform NeMo burn-in for AI workload testing",
    "Interpret burn-in test results and metrics",
    "Identify stability issues from extended testing",
    "Understand production readiness criteria"
  ],
  "faults": [],
  "initialClusterState": {},
  "steps": [
    {
      "id": "step1",
      "title": "Run NCCL Burn-in Test",
      "description": "Execute extended NCCL testing to validate network stability over multiple iterations. NCCL burn-in tests the collective communication infrastructure by running AllReduce operations repeatedly, exposing intermittent network issues.",
      "objectives": [
        "Run nccl-test with burn-in flag",
        "Monitor bandwidth consistency across iterations",
        "Verify zero failures over iterations",
        "Understand NCCL burn-in metrics"
      ],
      "expectedCommands": [
        "nccl-test --burn-in",
        "nccl-test --burn-in --iterations 100",
        "nccl-test --burn-in --iterations 1000"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must run NCCL burn-in test",
          "expectedCommands": ["nccl-test --burn-in"]
        }
      ],
      "hints": [
        "Burn-in tests run the same test repeatedly to find intermittent issues",
        "Look for consistent bandwidth across all iterations (280-300 GB/s)",
        "Any failures indicate unstable network or GPU connectivity",
        "Typical NCCL burn-in runs 100-1000 iterations",
        "Default is 1000 iterations if not specified",
        "Each iteration tests AllReduce collective operations"
      ],
      "estimatedDuration": 8,
      "documentationLinks": [
        {
          "title": "NCCL Tests Documentation",
          "url": "https://github.com/NVIDIA/nccl-tests"
        }
      ]
    },
    {
      "id": "step2",
      "title": "Run HPL Burn-in Test",
      "description": "Perform extended HPL (High-Performance Linpack) testing to validate compute stability and thermal management. HPL burn-in generates maximum heat load and tests power delivery under sustained compute.",
      "objectives": [
        "Execute HPL burn-in test",
        "Monitor performance consistency (450-500 TFLOPS)",
        "Verify thermal stability",
        "Check for performance degradation"
      ],
      "expectedCommands": [
        "hpl --burn-in",
        "hpl --burn-in --iterations 50",
        "nvidia-smi dmon -s pucvmet"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must run HPL burn-in test",
          "expectedCommands": ["hpl --burn-in"]
        }
      ],
      "hints": [
        "HPL burn-in validates compute and power delivery",
        "Each iteration generates significant heat load",
        "Performance should remain consistent across iterations",
        "Watch for thermal throttling in nvidia-smi output",
        "Default is 100 iterations if not specified",
        "Use --N flag to specify problem size (default: 90000)",
        "Monitor GPU temperatures during test"
      ],
      "estimatedDuration": 10,
      "documentationLinks": [
        {
          "title": "HPL Benchmarking Guide",
          "url": "https://www.netlib.org/benchmark/hpl/"
        }
      ]
    },
    {
      "id": "step3",
      "title": "Run NeMo AI Training Burn-in",
      "description": "Execute NeMo burn-in to validate AI training workload stability. NeMo burn-in simulates real training iterations with loss tracking, throughput monitoring, and GPU memory management validation.",
      "objectives": [
        "Run NeMo burn-in test",
        "Monitor training throughput (28K-30K tokens/sec)",
        "Verify GPU utilization stays high (>95%)",
        "Check for memory errors",
        "Validate loss convergence stability"
      ],
      "expectedCommands": [
        "nemo burn-in",
        "nemo burn-in --iterations 50",
        "nemo burnin --iterations 100",
        "nvidia-smi"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must run NeMo burn-in test",
          "expectedCommands": ["nemo burn-in", "nemo burnin"]
        }
      ],
      "hints": [
        "NeMo burn-in simulates real AI training workloads",
        "Training loss should decrease consistently",
        "GPU utilization should remain above 95%",
        "Memory errors indicate GPU hardware issues",
        "Default is 50 iterations for NeMo burn-in",
        "Throughput should remain stable around 29K tokens/sec",
        "Both 'burn-in' and 'burnin' flags work"
      ],
      "estimatedDuration": 12,
      "documentationLinks": [
        {
          "title": "NVIDIA NeMo Framework",
          "url": "https://docs.nvidia.com/nemo-framework/"
        }
      ]
    },
    {
      "id": "step4",
      "title": "Analyze Burn-in Results",
      "description": "Review results from all burn-in tests to assess cluster production readiness. Compare metrics across test types and identify any performance degradation or instability patterns.",
      "objectives": [
        "Compare results across all burn-in types",
        "Identify any performance degradation",
        "Verify zero failures across all tests",
        "Document baseline performance metrics",
        "Assess production readiness"
      ],
      "expectedCommands": [
        "nccl-test --burn-in --iterations 100",
        "hpl --burn-in --iterations 50",
        "nemo burn-in --iterations 50"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must review all burn-in test types",
          "expectedCommands": [
            "nccl-test --burn-in",
            "hpl --burn-in",
            "nemo burn-in"
          ],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "All tests should report PASSED status",
        "Look for minimum/average/maximum performance metrics",
        "Performance variance should be minimal (<5%)",
        "Zero failures indicates stable cluster",
        "NCCL: 280-300 GB/s bandwidth",
        "HPL: 450-500 TFLOPS performance",
        "NeMo: 28K-30K tokens/sec throughput",
        "Document results for future comparison"
      ],
      "estimatedDuration": 10,
      "documentationLinks": []
    },
    {
      "id": "step5",
      "title": "Production Readiness Checklist",
      "description": "Complete final validation checklist for production deployment. Verify all burn-in tests passed, confirm cluster health with ClusterKit, and document performance baselines for operational monitoring.",
      "objectives": [
        "Verify all burn-in tests passed",
        "Confirm cluster health with ClusterKit",
        "Validate firmware versions with fw-check",
        "Check signal quality with cable validation",
        "Document performance baselines",
        "Sign off on production readiness"
      ],
      "expectedCommands": [
        "clusterkit --verbose",
        "fw-check all",
        "ibdiagnet --detailed",
        "nvidia-smi topo -m"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must complete comprehensive health validation",
          "expectedCommands": ["clusterkit", "fw-check"]
        }
      ],
      "hints": [
        "Use ClusterKit for final comprehensive check",
        "All GPUs should show healthy status",
        "Network topology should be optimal",
        "Firmware should be current on all components",
        "Signal quality metrics should pass thresholds",
        "Document baseline performance for future comparison",
        "Zero burn-in failures = production ready"
      ],
      "estimatedDuration": 10,
      "documentationLinks": [
        {
          "title": "DGX SuperPOD Deployment Guide",
          "url": "https://docs.nvidia.com/dgx-superpod/"
        }
      ]
    }
  ],
  "tags": [
    "burn-in",
    "nccl",
    "hpl",
    "nemo",
    "performance",
    "stability",
    "advanced",
    "domain4"
  ],
  "tier": 3,
  "commandFamilies": ["gpu-monitoring", "infiniband-tools", "diagnostics"],
  "explanationGateId": "gate-domain4-burn-in",
  "toolHints": false
}
